{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def extraction_webscrapping(url, output_file, header_tag, keep_columns=None):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        print(\"Successfully fetched the webpage.\")\n",
    "    else:\n",
    "        print(f\"Failed to fetch the webpage: {response.status_code}\")\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    table = soup.find('table')\n",
    "    \n",
    "    headers = [th.text.strip() for th in table.find('thead').find_all(header_tag)]\n",
    "    print(f\"Headers found: {headers}\")\n",
    "    \n",
    "    rows = []\n",
    "    for tr in table.find('tbody').find_all('tr'):\n",
    "        cells = tr.find_all('td')\n",
    "        row = [cell.text.strip() for cell in cells]\n",
    "        rows.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(rows, columns=headers)\n",
    "    \n",
    "    if keep_columns:\n",
    "        print(f\"Filtering to keep columns: {keep_columns}\")\n",
    "        df = df[keep_columns]\n",
    "\n",
    "    # Ensure only the top 50 players\n",
    "    df = df.head(50)\n",
    "    \n",
    "    # Drop unnecessary columns\n",
    "    df.drop(columns=['Team', 'Pos'], inplace=True, errors='ignore')\n",
    "    \n",
    "    output_path = os.path.join('csv', output_file)\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Data successfully scraped and saved to {output_file}\")\n",
    "\n",
    "# Fetch and parse each required stat, keeping only the necessary columns and limiting to top 50 players\n",
    "extraction_webscrapping(\"https://www.teamrankings.com/nba/player-stat/points\", 'player-stat_2024.csv', 'th', ['Player', 'Value'])\n",
    "extraction_webscrapping(\"https://www.teamrankings.com/nba/player-stat/assists\", 'assists_2024.csv', 'th', ['Player', 'Value'])\n",
    "extraction_webscrapping(\"https://www.teamrankings.com/nba/player-stat/rebounds-offensive\", 'rebounds-offensive.csv', 'th', ['Player', 'Value'])\n",
    "extraction_webscrapping(\"https://www.teamrankings.com/nba/player-stat/rebounds-defensive\", 'rebounds-defensive.csv', 'th', ['Player', 'Value'])\n",
    "extraction_webscrapping(\"https://www.teamrankings.com/nba/player-stat/blocks\", 'blocks.csv', 'th', ['Player', 'Value'])\n",
    "extraction_webscrapping(\"https://www.teamrankings.com/nba/player-stat/steals\", 'steals.csv', 'th', ['Player', 'Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def load_and_extract_all(csv_file, value_column, col_rename):\n",
    "    df = pd.read_csv(os.path.join('csv', csv_file))\n",
    "    df.rename(columns={value_column: col_rename}, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Load data for each relevant statistic\n",
    "df_assists = load_and_extract_all('assists_2024.csv', 'Value', 'AST')\n",
    "df_player_stats = load_and_extract_all('player-stat_2024.csv', 'Value', 'PTS')\n",
    "df_OR = load_and_extract_all('rebounds-offensive.csv', 'Value', 'ORB')\n",
    "df_DRB = load_and_extract_all('rebounds-defensive.csv', 'Value', 'DRB')\n",
    "df_BLK = load_and_extract_all('blocks.csv', 'Value', 'BLK')\n",
    "df_STL = load_and_extract_all('steals.csv', 'Value', 'STL')\n",
    "\n",
    "# Ensure player names consistency\n",
    "def ensure_consistent_names(df):\n",
    "    df['Player'] = df['Player'].str.strip()\n",
    "    return df\n",
    "\n",
    "df_assists = ensure_consistent_names(df_assists)\n",
    "df_player_stats = ensure_consistent_names(df_player_stats)\n",
    "df_OR = ensure_consistent_names(df_OR)\n",
    "df_DRB = ensure_consistent_names(df_DRB)\n",
    "df_BLK = ensure_consistent_names(df_BLK)\n",
    "df_STL = ensure_consistent_names(df_STL)\n",
    "\n",
    "# Merge dataframes for Offensive PER\n",
    "df_combined_offense = df_player_stats.merge(df_assists, on=\"Player\", how='outer').merge(df_OR, on=\"Player\", how='outer')\n",
    "\n",
    "# Calculate Offensive PER only where data is complete\n",
    "df_combined_offense['O_PER'] = df_combined_offense[['PTS', 'AST', 'ORB']].dropna().apply(lambda row: (row['PTS'] + row['AST'] + row['ORB']) / 3, axis=1).round(1)\n",
    "\n",
    "# Retain top 50 players based on Offensive PER\n",
    "df_combined_offense = df_combined_offense.dropna(subset=['O_PER']).sort_values(by='O_PER', ascending=False).head(50)\n",
    "df_combined_offense.to_csv('nba_top_50_offensive_per.csv', index=False)\n",
    "print(\"Top 50 Offensive PER data saved to 'nba_top_50_offensive_per.csv'.\")\n",
    "\n",
    "# Merge dataframes for Defensive PER\n",
    "df_combined_defense = df_DRB.merge(df_BLK, on=\"Player\", how='outer').merge(df_STL, on=\"Player\", how='outer')\n",
    "\n",
    "# Calculate Defensive PER only where data is complete\n",
    "df_combined_defense['D_PER'] = df_combined_defense[['DRB', 'BLK', 'STL']].dropna().apply(lambda row: (row['DRB'] + row['BLK'] + row['STL']) / 3, axis=1).round(1)\n",
    "\n",
    "# Retain top 50 players based on Defensive PER\n",
    "df_combined_defense = df_combined_defense.dropna(subset=['D_PER']).sort_values(by='D_PER', ascending=False).head(50)\n",
    "df_combined_defense.to_csv('nba_top_50_defensive_per.csv', index=False)\n",
    "print(\"Top 50 Defensive PER data saved to 'nba_top_50_defensive_per.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
