{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully fetched the webpage: https://hoopshype.com/salaries/players/2023-2024/\n",
      "Headers found: ['', 'Player', '2023/24', '2023/24(*)']\n",
      "Data successfully scraped and saved to nba_player_salaries_2024.csv\n",
      "Successfully fetched the webpage: https://hoopshype.com/salaries/2023-2024/\n",
      "Headers found: ['', 'Team', '2023/24', '2023/24(*)']\n",
      "Data successfully scraped and saved to nba_team_salaries_2024.csv\n",
      "Successfully fetched the webpage: https://herhoopstats.com/salary-cap-sheet/wnba/players/salary_2024/stats_2024/\n",
      "Data successfully scraped and saved to wnba_player_salaries_2024.csv\n",
      "Successfully fetched the webpage: https://herhoopstats.com/salary-cap-sheet/wnba/summary/2024/\n",
      "Headers found: ['Team', 'Total Salaries', 'Total Players', 'Cap Room', 'Guaranteed Salaries']\n",
      "Filtering to keep columns: ['Team', 'Total Salaries']\n",
      "Data successfully scraped and saved to wnba_team_salaries_2024.csv\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root directory to PYTHONPATH:\n",
    "project_root = os.path.abspath(os.path.join(os.path.dirname(os.getcwd()), 'project'))\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "# Import extraction functions:\n",
    "from data_extraction.nba import extract_nba_player_salaries, extract_nba_team_salaries\n",
    "from data_extraction.wnba import extract_wnba_player_salaries, extract_wnba_team_salaries\n",
    "\n",
    "# Extract NBA player salaries:\n",
    "extract_nba_player_salaries(\"https://hoopshype.com/salaries/players/2023-2024/\", 'nba_player_salaries_2024.csv')\n",
    "\n",
    "# Extract NBA team salaries:\n",
    "extract_nba_team_salaries(\"https://hoopshype.com/salaries/2023-2024/\", 'nba_team_salaries_2024.csv')\n",
    "\n",
    "# Extract WNBA player salaries:\n",
    "extract_wnba_player_salaries(\"https://herhoopstats.com/salary-cap-sheet/wnba/players/salary_2024/stats_2024/\", 'wnba_player_salaries_2024.csv')\n",
    "\n",
    "# Extract WNBA team salaries:\n",
    "extract_wnba_team_salaries(\"https://herhoopstats.com/salary-cap-sheet/wnba/summary/2024/\", 'wnba_team_salaries_2024.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\$'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\$'\n",
      "C:\\Users\\Marc Jay\\AppData\\Local\\Temp\\ipykernel_5928\\2946843670.py:3: SyntaxWarning: invalid escape sequence '\\$'\n",
      "  \"\"\"import pandas as pd\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'import pandas as pd\\n\\n# Loading CSV:\\ndf = pd.read_csv(\\'wnba_player_salaries_2024.csv\\')\\n\\n# Convert Salary column to numeric:\\ndf = df[df[\\'2024 Salary\\'].str.startswith(\\'$\\', na=False)]\\ndf[\\'2024 Salary\\'] = df[\\'2024 Salary\\'].replace(r\\'[\\\\$,]\\', \\'\\', regex=True).astype(float)\\n\\n# Remove duplicates, keep highest salary:\\ndf_cleaned = df.sort_values(\\'2024 Salary\\', ascending=False).drop_duplicates(subset=[\\'Player\\'], keep=\\'first\\')\\n\\n# Created new \"cleaned_\" CSV:\\ndf_cleaned.to_csv(\\'cleaned_wnba_player_salaries_2024.csv\\', index=False)\\nprint(\"Cleaned data saved to \\'cleaned_wnba_player_salaries_2024.csv\\'.\")'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting to NUMERIC placeholder:\n",
    "\n",
    "\"\"\"import pandas as pd\n",
    "\n",
    "# Loading CSV:\n",
    "df = pd.read_csv('wnba_player_salaries_2024.csv')\n",
    "\n",
    "# Convert Salary column to numeric:\n",
    "df = df[df['2024 Salary'].str.startswith('$', na=False)]\n",
    "df['2024 Salary'] = df['2024 Salary'].replace(r'[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "# Remove duplicates, keep highest salary:\n",
    "df_cleaned = df.sort_values('2024 Salary', ascending=False).drop_duplicates(subset=['Player'], keep='first')\n",
    "\n",
    "# Created new \"cleaned_\" CSV:\n",
    "df_cleaned.to_csv('cleaned_wnba_player_salaries_2024.csv', index=False)\n",
    "print(\"Cleaned data saved to 'cleaned_wnba_player_salaries_2024.csv'.\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully fetched the webpage: https://herhoopstats.com/salary-cap-sheet/wnba/players/salary_2024/stats_2024/\n",
      "Initial DataFrame after extracting relevant columns (Offensive):\n",
      "             Player   PTS  AST  ORB\n",
      "0       A'ja Wilson  26.9  2.3  2.1\n",
      "1  Arike Ogunbowale  22.2  5.1  0.8\n",
      "2    Kahleah Copper  21.1  2.3  0.6\n",
      "3   Breanna Stewart  20.4  3.5  1.6\n",
      "4  Napheesa Collier  20.4  3.4  2.2\n",
      "Top 50 Offensive data with O-PER saved to 'wnba_top_50_offensive_per.csv'\n",
      "Final Cleaned Offensive DataFrame with O-PER:\n",
      "             Player   PTS  AST  ORB  O-PER\n",
      "0       A'ja Wilson  26.9  2.3  2.1   10.4\n",
      "1  Arike Ogunbowale  22.2  5.1  0.8    9.4\n",
      "2    Kahleah Copper  21.1  2.3  0.6    8.0\n",
      "3   Breanna Stewart  20.4  3.5  1.6    8.5\n",
      "4  Napheesa Collier  20.4  3.4  2.2    8.7\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Define the URL for WNBA Offensive Stats\n",
    "offensive_url = \"https://herhoopstats.com/salary-cap-sheet/wnba/players/salary_2024/stats_2024/\"\n",
    "\n",
    "# Function to fetch and parse data\n",
    "def fetch_and_parse(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        print(f\"Successfully fetched the webpage: {url}\")\n",
    "    else:\n",
    "        raise Exception(f\"Failed to fetch the webpage: {response.status_code}\")\n",
    "    return BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Function to extract relevant table data and clean it\n",
    "def extract_and_clean_relevant_data(soup, relevant_columns):\n",
    "    table = soup.find('table')\n",
    "    headers = [th.text.strip() for th in table.find('thead').find_all('th')]\n",
    "    columns_indices = {header: index for index, header in enumerate(headers) if header in relevant_columns}\n",
    "\n",
    "    rows = []\n",
    "    for tr in table.find('tbody').find_all('tr'):\n",
    "        cells = tr.find_all('td')\n",
    "        if len(cells) < len(relevant_columns):\n",
    "            continue  # Skip rows with incomplete data\n",
    "        row = {}\n",
    "        for header in relevant_columns:\n",
    "            index = columns_indices[header]\n",
    "            if index < len(cells):\n",
    "                value = cells[index].text.strip().split('\\n')[0]\n",
    "                row[header] = value\n",
    "            else:\n",
    "                row[header] = None\n",
    "        rows.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(rows, columns=relevant_columns)\n",
    "    return df\n",
    "\n",
    "# Fetch, parse, and extract data for Offensive Players\n",
    "soup_offensive = fetch_and_parse(offensive_url)\n",
    "relevant_columns_offensive = [\"Player\", \"PTS\", \"AST\", \"ORB\"]\n",
    "offensive_df = extract_and_clean_relevant_data(soup_offensive, relevant_columns_offensive)\n",
    "\n",
    "print(\"Initial DataFrame after extracting relevant columns (Offensive):\")\n",
    "print(offensive_df.head())\n",
    "\n",
    "# Clean the DataFrame\n",
    "offensive_df = offensive_df.dropna(subset=[\"PTS\", \"AST\", \"ORB\"])\n",
    "offensive_df[\"PTS\"] = pd.to_numeric(offensive_df[\"PTS\"], errors=\"coerce\")\n",
    "offensive_df[\"AST\"] = pd.to_numeric(offensive_df[\"AST\"], errors=\"coerce\")\n",
    "offensive_df[\"ORB\"] = pd.to_numeric(offensive_df[\"ORB\"], errors=\"coerce\")\n",
    "offensive_df = offensive_df.dropna(subset=[\"PTS\", \"AST\", \"ORB\"])\n",
    "\n",
    "# Extract Top 50 Scorers\n",
    "top_50_offensive_df = offensive_df.nlargest(50, \"PTS\")\n",
    "\n",
    "# Calculate Offensive PER\n",
    "top_50_offensive_df[\"O-PER\"] = (top_50_offensive_df[\"PTS\"] + top_50_offensive_df[\"AST\"] + top_50_offensive_df[\"ORB\"]) / 3\n",
    "\n",
    "# Round O-PER to one decimal place\n",
    "top_50_offensive_df[\"O-PER\"] = top_50_offensive_df[\"O-PER\"].round(1)\n",
    "\n",
    "# Ensure only relevant columns are included in the final CSV\n",
    "final_columns_offensive = [\"Player\", \"PTS\", \"AST\", \"ORB\", \"O-PER\"]\n",
    "top_50_offensive_df = top_50_offensive_df[final_columns_offensive]\n",
    "\n",
    "# Save to CSV\n",
    "top_50_offensive_df.to_csv(\"wnba_top_50_offensive_per.csv\", index=False)\n",
    "print(\"Top 50 Offensive data with O-PER saved to 'wnba_top_50_offensive_per.csv'\")\n",
    "\n",
    "print(\"Final Cleaned Offensive DataFrame with O-PER:\")\n",
    "print(top_50_offensive_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully fetched the webpage: https://herhoopstats.com/salary-cap-sheet/wnba/players/salary_2024/stats_2024/\n",
      "Initial DataFrame after extracting relevant columns (Defensive):\n",
      "             Player  DRB  BLK  STL\n",
      "0       A'ja Wilson  9.8  2.6  1.8\n",
      "1  Arike Ogunbowale  3.8  0.3  2.1\n",
      "2    Kahleah Copper  3.9  0.1  0.8\n",
      "3   Breanna Stewart  6.9  1.3  1.7\n",
      "4  Napheesa Collier  7.5  1.4  1.9\n",
      "Top 50 Defensive data with D-PER saved to 'wnba_top_50_defensive_per.csv'\n",
      "Final Cleaned Defensive DataFrame with D-PER:\n",
      "              Player  DRB  BLK  STL  D-PER\n",
      "0        A'ja Wilson  9.8  2.6  1.8    4.7\n",
      "29       Angel Reese  8.1  0.5  1.3    3.3\n",
      "15     Dearica Hamby  7.7  0.2  1.7    3.2\n",
      "4   Napheesa Collier  7.5  1.4  1.9    3.6\n",
      "26     Jonquel Jones  7.3  1.3  0.8    3.1\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Define the URL for WNBA Defensive Stats\n",
    "defensive_url = \"https://herhoopstats.com/salary-cap-sheet/wnba/players/salary_2024/stats_2024/\"\n",
    "\n",
    "# Function to fetch and parse data\n",
    "def fetch_and_parse(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        print(f\"Successfully fetched the webpage: {url}\")\n",
    "    else:\n",
    "        raise Exception(f\"Failed to fetch the webpage: {response.status_code}\")\n",
    "    return BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Function to extract relevant table data and clean it\n",
    "def extract_and_clean_relevant_data(soup, relevant_columns):\n",
    "    table = soup.find('table')\n",
    "    headers = [th.text.strip() for th in table.find('thead').find_all('th')]\n",
    "    columns_indices = {header: index for index, header in enumerate(headers) if header in relevant_columns}\n",
    "\n",
    "    rows = []\n",
    "    for tr in table.find('tbody').find_all('tr'):\n",
    "        cells = tr.find_all('td')\n",
    "        if len(cells) < len(relevant_columns):\n",
    "            continue  # Skip rows with incomplete data\n",
    "        row = {}\n",
    "        for header in relevant_columns:\n",
    "            index = columns_indices[header]\n",
    "            if index < len(cells):\n",
    "                value = cells[index].text.strip().split('\\n')[0]\n",
    "                row[header] = value\n",
    "            else:\n",
    "                row[header] = None\n",
    "        rows.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(rows, columns=relevant_columns)\n",
    "    return df\n",
    "\n",
    "# Fetch, parse, and extract data for Defensive Players\n",
    "soup_defensive = fetch_and_parse(defensive_url)\n",
    "relevant_columns_defensive = [\"Player\", \"DRB\", \"BLK\", \"STL\"]\n",
    "defensive_df = extract_and_clean_relevant_data(soup_defensive, relevant_columns_defensive)\n",
    "\n",
    "print(\"Initial DataFrame after extracting relevant columns (Defensive):\")\n",
    "print(defensive_df.head())\n",
    "\n",
    "# Clean the DataFrame\n",
    "defensive_df = defensive_df.dropna(subset=[\"DRB\", \"BLK\", \"STL\"])\n",
    "defensive_df[\"DRB\"] = pd.to_numeric(defensive_df[\"DRB\"], errors=\"coerce\")\n",
    "defensive_df[\"BLK\"] = pd.to_numeric(defensive_df[\"BLK\"], errors=\"coerce\")\n",
    "defensive_df[\"STL\"] = pd.to_numeric(defensive_df[\"STL\"], errors=\"coerce\")\n",
    "defensive_df = defensive_df.dropna(subset=[\"DRB\", \"BLK\", \"STL\"])\n",
    "\n",
    "# Extract Top 50 Defensive Rebounders\n",
    "top_50_defensive_df = defensive_df.nlargest(50, \"DRB\")\n",
    "\n",
    "# Calculate Defensive PER\n",
    "top_50_defensive_df[\"D-PER\"] = (top_50_defensive_df[\"DRB\"] + top_50_defensive_df[\"BLK\"] + top_50_defensive_df[\"STL\"]) / 3\n",
    "\n",
    "# Round D-PER to one decimal place\n",
    "top_50_defensive_df[\"D-PER\"] = top_50_defensive_df[\"D-PER\"].round(1)\n",
    "\n",
    "# Ensure only relevant columns are included in the final CSV\n",
    "final_columns_defensive = [\"Player\", \"DRB\", \"BLK\", \"STL\", \"D-PER\"]\n",
    "top_50_defensive_df = top_50_defensive_df[final_columns_defensive]\n",
    "\n",
    "# Save to CSV\n",
    "top_50_defensive_df.to_csv(\"wnba_top_50_defensive_per.csv\", index=False)\n",
    "print(\"Top 50 Defensive data with D-PER saved to 'wnba_top_50_defensive_per.csv'\")\n",
    "\n",
    "print(\"Final Cleaned Defensive DataFrame with D-PER:\")\n",
    "print(top_50_defensive_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
