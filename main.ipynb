{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully fetched the webpage: https://hoopshype.com/salaries/players/2023-2024/\n",
      "Headers found: ['', 'Player', '2023/24', '2023/24(*)']\n",
      "Data successfully scraped and saved to nba_player_salaries_2024.csv\n",
      "Successfully fetched the webpage: https://hoopshype.com/salaries/2023-2024/\n",
      "Headers found: ['', 'Team', '2023/24', '2023/24(*)']\n",
      "Data successfully scraped and saved to nba_team_salaries_2024.csv\n",
      "Successfully fetched the webpage: https://herhoopstats.com/salary-cap-sheet/wnba/players/salary_2024/stats_2024/\n",
      "Data successfully scraped and saved to wnba_player_salaries_2024.csv\n",
      "Successfully fetched the webpage: https://herhoopstats.com/salary-cap-sheet/wnba/summary/2024/\n",
      "Headers found: ['Team', 'Total Salaries', 'Total Players', 'Cap Room', 'Guaranteed Salaries']\n",
      "Filtering to keep columns: ['Team', 'Total Salaries']\n",
      "Data successfully scraped and saved to wnba_team_salaries_2024.csv\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.path.dirname(os.getcwd()), 'project'))\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "from data_extraction.nba import extract_nba_player_salaries, extract_nba_team_salaries\n",
    "from data_extraction.wnba import extract_wnba_player_salaries, extract_wnba_team_salaries\n",
    "\n",
    "extract_nba_player_salaries(\"https://hoopshype.com/salaries/players/2023-2024/\", 'nba_player_salaries_2024.csv')\n",
    "extract_nba_team_salaries(\"https://hoopshype.com/salaries/2023-2024/\", 'nba_team_salaries_2024.csv')\n",
    "extract_wnba_player_salaries(\"https://herhoopstats.com/salary-cap-sheet/wnba/players/salary_2024/stats_2024/\", 'wnba_player_salaries_2024.csv')\n",
    "extract_wnba_team_salaries(\"https://herhoopstats.com/salary-cap-sheet/wnba/summary/2024/\", 'wnba_team_salaries_2024.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to 'cleaned_wnba_player_salaries_2024.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading CSV:\n",
    "df = pd.read_csv('wnba_player_salaries_2024.csv')\n",
    "\n",
    "# Convert Salary column to numeric:\n",
    "df = df[df['2024 Salary'].str.startswith('$', na=False)]\n",
    "df['2024 Salary'] = df['2024 Salary'].replace(r'[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "# Remove duplicates, keep highest salary:\n",
    "df_cleaned = df.sort_values('2024 Salary', ascending=False).drop_duplicates(subset=['Player'], keep='first')\n",
    "\n",
    "# Created new \"cleaned_\" CSV:\n",
    "df_cleaned.to_csv('cleaned_wnba_player_salaries_2024.csv', index=False)\n",
    "print(\"Cleaned data saved to 'cleaned_wnba_player_salaries_2024.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully fetched the webpage: https://herhoopstats.com/salary-cap-sheet/wnba/players/salary_2024/stats_2024/\n",
      "DataFrame after extracting relevant columns:\n",
      "                                              Player   G   PTS  AST\n",
      "0  A'ja Wilson\\n                          \\n\\n   ...  38  26.9  2.3\n",
      "1  Arike Ogunbowale\\n                          \\n...  38  22.2  5.1\n",
      "2  Kahleah Copper\\n                          \\n\\n...  37  21.1  2.3\n",
      "3  Breanna Stewart\\n                          \\n\\...  38  20.4  3.5\n",
      "4  Napheesa Collier\\n                          \\n...  34  20.4  3.4\n",
      "Data with PER saved to 'wnba_per.csv'\n",
      "Final DataFrame with PER:\n",
      "                                              Player   G   PTS  AST        PER\n",
      "0  A'ja Wilson\\n                          \\n\\n   ...  38  26.9  2.3  22.400000\n",
      "1  Arike Ogunbowale\\n                          \\n...  38  22.2  5.1  21.766667\n",
      "2  Kahleah Copper\\n                          \\n\\n...  37  21.1  2.3  20.133333\n",
      "3  Breanna Stewart\\n                          \\n\\...  38  20.4  3.5  20.633333\n",
      "4  Napheesa Collier\\n                          \\n...  34  20.4  3.4  19.266667\n",
      "Data types in the final DataFrame:\n",
      "Player     object\n",
      "G           int64\n",
      "PTS       float64\n",
      "AST       float64\n",
      "PER       float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL for WNBA Stats\n",
    "url = \"https://herhoopstats.com/salary-cap-sheet/wnba/players/salary_2024/stats_2024/\"\n",
    "\n",
    "# Function to fetch and parse data\n",
    "def fetch_and_parse(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        print(f\"Successfully fetched the webpage: {url}\")\n",
    "    else:\n",
    "        raise Exception(f\"Failed to fetch the webpage: {response.status_code}\")\n",
    "    return BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Function to extract relevant table data\n",
    "def extract_relevant_data(soup):\n",
    "    table = soup.find('table')\n",
    "\n",
    "    # Extract headers\n",
    "    headers = [th.text.strip() for th in table.find('thead').find_all('th')]\n",
    "\n",
    "    # Identify the relevant columns indices\n",
    "    relevant_columns = {header: index for index, header in enumerate(headers) if header in [\"Player\", \"G\", \"PTS\", \"AST\"]}\n",
    "    \n",
    "    # Extract rows with necessary columns\n",
    "    rows = []\n",
    "    for tr in table.find('tbody').find_all('tr'):\n",
    "        cells = tr.find_all('td')\n",
    "        row = {header: cells[idx].text.strip() for header, idx in relevant_columns.items()}\n",
    "        rows.append(row)\n",
    "    \n",
    "    # Create DataFrame with extracted columns\n",
    "    df = pd.DataFrame(rows, columns=relevant_columns.keys())\n",
    "    return df\n",
    "\n",
    "# Fetch, parse, and extract data\n",
    "soup = fetch_and_parse(url)\n",
    "relevant_df = extract_relevant_data(soup)\n",
    "\n",
    "print(\"DataFrame after extracting relevant columns:\")\n",
    "print(relevant_df.head())\n",
    "\n",
    "# Convert the columns to numeric\n",
    "relevant_df['G'] = pd.to_numeric(relevant_df['G'], errors='coerce')\n",
    "relevant_df['PTS'] = pd.to_numeric(relevant_df['PTS'], errors='coerce')\n",
    "relevant_df['AST'] = pd.to_numeric(relevant_df['AST'], errors='coerce')\n",
    "\n",
    "# Calculate PER\n",
    "relevant_df['PER'] = (relevant_df['G'] + relevant_df['PTS'] + relevant_df['AST']) / 3\n",
    "\n",
    "# Save the DataFrame with PER to CSV\n",
    "relevant_df.to_csv('wnba_per.csv', index=False)\n",
    "print(\"Data with PER saved to 'wnba_per.csv'\")\n",
    "\n",
    "# Confirm the final DataFrame\n",
    "print(\"Final DataFrame with PER:\")\n",
    "print(relevant_df.head())\n",
    "\n",
    "# Checking data types to ensure everything is in numeric format\n",
    "print(\"Data types in the final DataFrame:\")\n",
    "print(relevant_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
