{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marc Jay\\Ironhack\\nba_vs_wbna\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\Marc Jay\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python312.zip', 'c:\\\\Users\\\\Marc Jay\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\DLLs', 'c:\\\\Users\\\\Marc Jay\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\Lib', 'c:\\\\Users\\\\Marc Jay\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312', '', 'C:\\\\Users\\\\Marc Jay\\\\AppData\\\\Roaming\\\\Python\\\\Python312\\\\site-packages', 'C:\\\\Users\\\\Marc Jay\\\\AppData\\\\Roaming\\\\Python\\\\Python312\\\\site-packages\\\\win32', 'C:\\\\Users\\\\Marc Jay\\\\AppData\\\\Roaming\\\\Python\\\\Python312\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\Marc Jay\\\\AppData\\\\Roaming\\\\Python\\\\Python312\\\\site-packages\\\\Pythonwin', 'c:\\\\Users\\\\Marc Jay\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\Lib\\\\site-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'calculate_and_save_offensive_per' from 'data_extraction._offensive_per_wnba' (c:\\Users\\Marc Jay\\Ironhack\\nba_vs_wbna\\data_extraction\\_offensive_per_wnba.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwnba\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m extract_wnba_player_salaries, extract_wnba_team_salaries\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Import the new function for calculating WNBA Offensive PER\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_offensive_per_wnba\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m calculate_and_save_offensive_per\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Extract NBA player salaries\u001b[39;00m\n\u001b[0;32m     16\u001b[0m extract_nba_player_salaries(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://hoopshype.com/salaries/players/2023-2024/\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnba_player_salaries_2024.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'calculate_and_save_offensive_per' from 'data_extraction._offensive_per_wnba' (c:\\Users\\Marc Jay\\Ironhack\\nba_vs_wbna\\data_extraction\\_offensive_per_wnba.py)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the current directory to PYTHONPATH (assuming main.ipynb is at the same directory level as data_extraction folder)\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "# Import extraction functions\n",
    "from data_extraction.nba import extract_nba_player_salaries, extract_nba_team_salaries\n",
    "from data_extraction.wnba import extract_wnba_player_salaries, extract_wnba_team_salaries\n",
    "\n",
    "# Import the new function for calculating WNBA Offensive PER\n",
    "from data_extraction._offensive_per_wnba import calculate_and_save_offensive_per\n",
    "\n",
    "# Extract NBA player salaries\n",
    "extract_nba_player_salaries(\"https://hoopshype.com/salaries/players/2023-2024/\", 'nba_player_salaries_2024.csv')\n",
    "\n",
    "# Extract NBA team salaries\n",
    "extract_nba_team_salaries(\"https://hoopshype.com/salaries/2023-2024/\", 'nba_team_salaries_2024.csv')\n",
    "\n",
    "# Extract WNBA player salaries\n",
    "extract_wnba_player_salaries(\"https://herhoopstats.com/salary-cap-sheet/wnba/players/salary_2024/stats_2024/\", 'wnba_player_salaries_2024.csv')\n",
    "\n",
    "# Extract WNBA team salaries\n",
    "extract_wnba_team_salaries(\"https://herhoopstats.com/salary-cap-sheet/wnba/summary/2024/\", 'wnba_team_salaries_2024.csv')\n",
    "\n",
    "# Calculate and save Offensive PER for WNBA players\n",
    "calculate_and_save_offensive_per(\"https://herhoopstats.com/salary-cap-sheet/wnba/players/salary_2024/stats_2024/\", \"wnba_top_50_offensive_per.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to NUMERIC placeholder:\n",
    "\n",
    "\"\"\"import pandas as pd\n",
    "\n",
    "# Loading CSV:\n",
    "df = pd.read_csv('wnba_player_salaries_2024.csv')\n",
    "\n",
    "# Convert Salary column to numeric:\n",
    "df = df[df['2024 Salary'].str.startswith('$', na=False)]\n",
    "df['2024 Salary'] = df['2024 Salary'].replace(r'[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "# Remove duplicates, keep highest salary:\n",
    "df_cleaned = df.sort_values('2024 Salary', ascending=False).drop_duplicates(subset=['Player'], keep='first')\n",
    "\n",
    "# Created new \"cleaned_\" CSV:\n",
    "df_cleaned.to_csv('cleaned_wnba_player_salaries_2024.csv', index=False)\n",
    "print(\"Cleaned data saved to 'cleaned_wnba_player_salaries_2024.csv'.\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Define the URL for WNBA Offensive Stats\n",
    "offensive_url = \"https://herhoopstats.com/salary-cap-sheet/wnba/players/salary_2024/stats_2024/\"\n",
    "\n",
    "# Function to fetch and parse data\n",
    "def fetch_and_parse(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        print(f\"Successfully fetched the webpage: {url}\")\n",
    "    else:\n",
    "        raise Exception(f\"Failed to fetch the webpage: {response.status_code}\")\n",
    "    return BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Function to extract relevant table data and clean it\n",
    "def extract_and_clean_relevant_data(soup, relevant_columns):\n",
    "    table = soup.find('table')\n",
    "    headers = [th.text.strip() for th in table.find('thead').find_all('th')]\n",
    "    columns_indices = {header: index for index, header in enumerate(headers) if header in relevant_columns}\n",
    "\n",
    "    rows = []\n",
    "    for tr in table.find('tbody').find_all('tr'):\n",
    "        cells = tr.find_all('td')\n",
    "        if len(cells) < len(relevant_columns):\n",
    "            continue  # Skip rows with incomplete data\n",
    "        row = {}\n",
    "        for header in relevant_columns:\n",
    "            index = columns_indices[header]\n",
    "            if index < len(cells):\n",
    "                value = cells[index].text.strip().split('\\n')[0]\n",
    "                row[header] = value\n",
    "            else:\n",
    "                row[header] = None\n",
    "        rows.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(rows, columns=relevant_columns)\n",
    "    return df\n",
    "\n",
    "# Fetch, parse, and extract data for Offensive Players\n",
    "soup_offensive = fetch_and_parse(offensive_url)\n",
    "relevant_columns_offensive = [\"Player\", \"PTS\", \"AST\", \"ORB\"]\n",
    "offensive_df = extract_and_clean_relevant_data(soup_offensive, relevant_columns_offensive)\n",
    "\n",
    "print(\"Initial DataFrame after extracting relevant columns (Offensive):\")\n",
    "print(offensive_df.head())\n",
    "\n",
    "# Clean the DataFrame\n",
    "offensive_df = offensive_df.dropna(subset=[\"PTS\", \"AST\", \"ORB\"])\n",
    "offensive_df[\"PTS\"] = pd.to_numeric(offensive_df[\"PTS\"], errors=\"coerce\")\n",
    "offensive_df[\"AST\"] = pd.to_numeric(offensive_df[\"AST\"], errors=\"coerce\")\n",
    "offensive_df[\"ORB\"] = pd.to_numeric(offensive_df[\"ORB\"], errors=\"coerce\")\n",
    "offensive_df = offensive_df.dropna(subset=[\"PTS\", \"AST\", \"ORB\"])\n",
    "\n",
    "# Extract Top 50 Scorers\n",
    "top_50_offensive_df = offensive_df.nlargest(50, \"PTS\")\n",
    "\n",
    "# Calculate Offensive PER\n",
    "top_50_offensive_df[\"O-PER\"] = (top_50_offensive_df[\"PTS\"] + top_50_offensive_df[\"AST\"] + top_50_offensive_df[\"ORB\"]) / 3\n",
    "\n",
    "# Round O-PER to one decimal place\n",
    "top_50_offensive_df[\"O-PER\"] = top_50_offensive_df[\"O-PER\"].round(1)\n",
    "\n",
    "# Ensure only relevant columns are included in the final CSV\n",
    "final_columns_offensive = [\"Player\", \"PTS\", \"AST\", \"ORB\", \"O-PER\"]\n",
    "top_50_offensive_df = top_50_offensive_df[final_columns_offensive]\n",
    "\n",
    "# Save to CSV\n",
    "top_50_offensive_df.to_csv(\"wnba_top_50_offensive_per.csv\", index=False)\n",
    "print(\"Top 50 Offensive data with O-PER saved to 'wnba_top_50_offensive_per.csv'\")\n",
    "\n",
    "print(\"Final Cleaned Offensive DataFrame with O-PER:\")\n",
    "print(top_50_offensive_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Define the URL for WNBA Defensive Stats\n",
    "defensive_url = \"https://herhoopstats.com/salary-cap-sheet/wnba/players/salary_2024/stats_2024/\"\n",
    "\n",
    "# Function to fetch and parse data\n",
    "def fetch_and_parse(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        print(f\"Successfully fetched the webpage: {url}\")\n",
    "    else:\n",
    "        raise Exception(f\"Failed to fetch the webpage: {response.status_code}\")\n",
    "    return BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Function to extract relevant table data and clean it\n",
    "def extract_and_clean_relevant_data(soup, relevant_columns):\n",
    "    table = soup.find('table')\n",
    "    headers = [th.text.strip() for th in table.find('thead').find_all('th')]\n",
    "    columns_indices = {header: index for index, header in enumerate(headers) if header in relevant_columns}\n",
    "\n",
    "    rows = []\n",
    "    for tr in table.find('tbody').find_all('tr'):\n",
    "        cells = tr.find_all('td')\n",
    "        if len(cells) < len(relevant_columns):\n",
    "            continue  # Skip rows with incomplete data\n",
    "        row = {}\n",
    "        for header in relevant_columns:\n",
    "            index = columns_indices[header]\n",
    "            if index < len(cells):\n",
    "                value = cells[index].text.strip().split('\\n')[0]\n",
    "                row[header] = value\n",
    "            else:\n",
    "                row[header] = None\n",
    "        rows.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(rows, columns=relevant_columns)\n",
    "    return df\n",
    "\n",
    "# Fetch, parse, and extract data for Defensive Players\n",
    "soup_defensive = fetch_and_parse(defensive_url)\n",
    "relevant_columns_defensive = [\"Player\", \"DRB\", \"BLK\", \"STL\"]\n",
    "defensive_df = extract_and_clean_relevant_data(soup_defensive, relevant_columns_defensive)\n",
    "\n",
    "print(\"Initial DataFrame after extracting relevant columns (Defensive):\")\n",
    "print(defensive_df.head())\n",
    "\n",
    "# Clean the DataFrame\n",
    "defensive_df = defensive_df.dropna(subset=[\"DRB\", \"BLK\", \"STL\"])\n",
    "defensive_df[\"DRB\"] = pd.to_numeric(defensive_df[\"DRB\"], errors=\"coerce\")\n",
    "defensive_df[\"BLK\"] = pd.to_numeric(defensive_df[\"BLK\"], errors=\"coerce\")\n",
    "defensive_df[\"STL\"] = pd.to_numeric(defensive_df[\"STL\"], errors=\"coerce\")\n",
    "defensive_df = defensive_df.dropna(subset=[\"DRB\", \"BLK\", \"STL\"])\n",
    "\n",
    "# Extract Top 50 Defensive Rebounders\n",
    "top_50_defensive_df = defensive_df.nlargest(50, \"DRB\")\n",
    "\n",
    "# Calculate Defensive PER\n",
    "top_50_defensive_df[\"D-PER\"] = (top_50_defensive_df[\"DRB\"] + top_50_defensive_df[\"BLK\"] + top_50_defensive_df[\"STL\"]) / 3\n",
    "\n",
    "# Round D-PER to one decimal place\n",
    "top_50_defensive_df[\"D-PER\"] = top_50_defensive_df[\"D-PER\"].round(1)\n",
    "\n",
    "# Ensure only relevant columns are included in the final CSV\n",
    "final_columns_defensive = [\"Player\", \"DRB\", \"BLK\", \"STL\", \"D-PER\"]\n",
    "top_50_defensive_df = top_50_defensive_df[final_columns_defensive]\n",
    "\n",
    "# Save to CSV\n",
    "top_50_defensive_df.to_csv(\"wnba_top_50_defensive_per.csv\", index=False)\n",
    "print(\"Top 50 Defensive data with D-PER saved to 'wnba_top_50_defensive_per.csv'\")\n",
    "\n",
    "print(\"Final Cleaned Defensive DataFrame with D-PER:\")\n",
    "print(top_50_defensive_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
