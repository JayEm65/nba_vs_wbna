{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd \n",
    "\n",
    "# Season 2024 / All games\n",
    "# The number of points of a player\n",
    "url = \"https://www.teamrankings.com/nba/player-stat/points\"\n",
    "# Fetching HTML content:\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    print(\"Done! - Successfully fetched the webpage.\")\n",
    "else:\n",
    "    print(f\"Failed to fetch the webpage: {response.status_code}\")\n",
    "\n",
    "# Parsing HTML content:\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Inspect page and find table containing needed data (Assuming the data is in a table.):\n",
    "table = soup.find('table')\n",
    "type(table)\n",
    "\n",
    "# Extract headers:\n",
    "headers = []\n",
    "for th in table.find('thead').find_all('th'):\n",
    "    headers.append(th.text.strip())\n",
    "\n",
    "# Extract rows:\n",
    "rows = []\n",
    "for tr in table.find('tbody').find_all('tr'):\n",
    "    cells = tr.find_all('td')\n",
    "    row = [cell.text.strip() for cell in cells]\n",
    "    rows.append(row)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "# Save data to CSV:\n",
    "df.to_csv('player-stat_2024.csv', index=False)\n",
    "\n",
    "print(\"Data successfully scraped and saved to 'player-stat_2024.csv'\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def extraction_webscrapping(url, output_file, header_tag, keep_columns=None):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        print(\"Successfully fetched the webpage.\")\n",
    "    else:\n",
    "        print(f\"Failed to fetch the webpage: {response.status_code}\")\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    table = soup.find('table')\n",
    "    \n",
    "    headers = []\n",
    "    for th in table.find('thead').find_all(header_tag):\n",
    "        headers.append(th.text.strip())\n",
    "    print(f\"Headers found: {headers}\")\n",
    "    \n",
    "    rows = []\n",
    "    for tr in table.find('tbody').find_all('tr'):\n",
    "        cells = tr.find_all('td')\n",
    "        row = [cell.text.strip() for cell in cells]\n",
    "        rows.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(rows, columns=headers)\n",
    "    \n",
    "    if keep_columns:\n",
    "        print(f\"Filtering to keep columns: {keep_columns}\")\n",
    "        df = df[keep_columns]\n",
    "    \n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Data successfully scraped and saved to {output_file}\")\n",
    "\n",
    "def extract_wnba_player_salaries(url, output_file):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        print(\"Successfully fetched the webpage.\")\n",
    "    else:\n",
    "        print(f\"Failed to fetch the webpage: {response.status_code}\")\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    table = soup.find('table')\n",
    "    \n",
    "    headers = [\"Player\", \"2024 Salary\"]\n",
    "    rows = []\n",
    "    \n",
    "    for tr in table.find('tbody').find_all('tr'):\n",
    "        cells = tr.find_all('td')\n",
    "        name = cells[0].text.strip().split('\\n')[0]  # Only take first part for the name\n",
    "        salary = cells[1].text.strip().split()[0]    # Only take the salary amount\n",
    "        row = [name, salary]\n",
    "        rows.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(rows, columns=headers)\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Data successfully scraped and saved to {output_file}\")\n",
    "\n",
    "#Number of points of a player (per game)\n",
    "extraction_webscrapping(\"https://www.teamrankings.com/nba/player-stat/points\", 'player-stat_2024.csv', 'th')\n",
    "#Effective field goal % (per game):\n",
    "extraction_webscrapping(\"https://www.teamrankings.com/nba/player-stat/efg-percentage\", 'efg-percentage_2024.csv', 'th')\n",
    "#Assists (per game):\n",
    "extraction_webscrapping(\"https://www.teamrankings.com/nba/player-stat/assists\", 'assists_2024.csv', 'th')\n",
    "#Win score (per game):\n",
    "extraction_webscrapping(\"https://www.teamrankings.com/nba/player-stat/win-score\", 'win_score_2024.csv', 'th')\n",
    "#Minutes played (per game):\n",
    "extraction_webscrapping(\"https://www.teamrankings.com/nba/player-stat/minutes-played\",'minutes_played.csv','th')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "############  READ THE CSV ###########\n",
    "#Assists per game\n",
    "df_assists = pd.read_csv('assists_2024.csv')\n",
    "df_assists.rename(columns={'Value':'AST' } , inplace=True)\n",
    "display('Assists per game')\n",
    "display(df_assists)\n",
    "\n",
    "#Points per game\n",
    "df_player_stats = pd.read_csv('player-stat_2024.csv')\n",
    "df_player_stats.rename(columns={'Value':'PTS' } , inplace=True)\n",
    "display('Points per game')\n",
    "display(df_player_stats)\n",
    "\n",
    "#Games Played  --> Minutes Played ?!\n",
    "df_minutes_played = pd.read_csv('minutes_played.csv')\n",
    "df_player_stats.rename(columns={'Value':'Minutes_played_per_game' } , inplace=True)\n",
    "display('Minutes Played')\n",
    "display(df_minutes_played)\n",
    "\n",
    "#Offensive rebounds (per game):\n",
    "df_OR = pd.read_csv('rebounds-offensive.csv')\n",
    "df_OR.rename(columns={'Value':'ORB' } , inplace=True)\n",
    "display('Offensive rebounds per game')\n",
    "display(df_OR)\n",
    "#Defensive rebounds (per game):\n",
    "df_DRB = pd.read_csv('rebounds-defensive.csv')\n",
    "df_DRB.rename(columns={'Value':'DRB' } , inplace=True)\n",
    "display('Defensive rebounds per game')\n",
    "display(df_DRB)\n",
    "#Blocks (per game):\n",
    "df_BLK = pd.read_csv('blocks.csv')\n",
    "df_BLK.rename(columns={'Value':'BLK' } , inplace=True)\n",
    "display('Blocks per game')\n",
    "display(df_BLK)\n",
    "#Steal (per game):\n",
    "df_STL = pd.read_csv('steals.csv')\n",
    "df_STL.rename(columns={'Value':'STL' } , inplace=True)\n",
    "display('Steal per game')\n",
    "display(df_STL)\n",
    "\n",
    "############  Merge ###########\n",
    "\n",
    "#Merge vs points and assist (merged):\n",
    "df_points_and_assists = df_assists.merge(df_player_stats, on=[\"Player\" , \"Pos\", \"Team\"])\n",
    "display(\"Points and assist (merged):\")\n",
    "display(df_points_and_assists)\n",
    "\n",
    "#Final result: df_points_and_assists merged with df_OR (offensive rebounds) sorted by Points_per_game:\n",
    "second_merge = df_points_and_assists.merge(df_OR , on=[\"Player\" , \"Pos\", \"Team\"])\n",
    "second_merge.rename(columns={'Value':'Minutes_played_per_game' } , inplace=True)\n",
    "second_merge.sort_values(by=['PTS']).reset_index()\n",
    "# Remove of columns : Rank_x , Rank_y , (Pos also?)\n",
    "second_merge.drop(columns = ['Rank_x', 'Rank_y','Rank'] , axis=1, inplace=True)\n",
    "#second_merge.drop(columns = ['Rank_x', 'Rank_y'] , axis=1, inplace=True)\n",
    "#Finally, PER computation\n",
    "second_merge['PER'] = round((second_merge['AST'] + second_merge['PTS']  + second_merge['ORB'])/3 ,1)\n",
    "#second_merge.sort_values(by=['PTS']).reset_index()\n",
    "display(\"Points_and_assist merged with offensive rebounds and sorted by Points_per_game PTS (offensive PER rounded):\")\n",
    "display(second_merge)\n",
    "\n",
    "##### Defense Merge #####\n",
    "# a) Merge of PTS and df_DRB\n",
    "\n",
    "#second_merge[second_merge['PTS']].merge(df_DRB)\n",
    "# b) Merge df_DRB and df_BLK\n",
    "#df_DRB.merge(df_BLK , on=[\"Player\" , \"Pos\", \"Team\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
